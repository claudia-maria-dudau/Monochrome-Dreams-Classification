---- 0 ----
train: 11.029656781072976
validation: 11.360000000000001
loss: 15.919525258354515

---- 10 ----
train: 12.895701432855713
validation: 12.839999999999998
loss: 3.9574270911772156

---- 20 ----
train: 13.395534821726091
validation: 13.5
loss: 3.8142833868000134

---- 30 ----
train: 13.828723758747083
validation: 14.06
loss: 3.6824502673834636

---- 40 ----
train: 14.395201599466844
validation: 14.42
loss: 3.5609609436658984

---- 50 ----
train: 14.961679440186604
validation: 14.84
loss: 3.4490116299233784

---- 60 ----
train: 15.594801732755748
validation: 15.260000000000002
loss: 3.3458164674038824

---- 70 ----
train: 16.12795734755082
validation: 15.78
loss: 3.250633173502943

---- 80 ----
train: 16.92769076974342
validation: 16.580000000000002
loss: 3.162771166050306

---- 90 ----
train: 17.66077974008664
validation: 17.14
loss: 3.0815912989436582

---- 100 ----
train: 18.46051316227924
validation: 18.04
loss: 3.0065043160802554

---- 110 ----
train: 19.22692435854715
validation: 18.64
loss: 2.936969633777358

---- 120 ----
train: 19.826724425191603
validation: 19.34
loss: 2.8724934823699866

---- 130 ----
train: 20.55981339553482
validation: 20.080000000000002
loss: 2.812625910904634

---- 140 ----
train: 21.226257914028658
validation: 20.68
loss: 2.7569571972067024

---- 150 ----
train: 21.659446851049648
validation: 21.4
loss: 2.7051144007166252

---- 160 ----
train: 22.459180273242254
validation: 21.94
loss: 2.656758386942706

---- 170 ----
train: 23.025658113962013
validation: 22.259999999999998
loss: 2.6115812680535164

---- 180 ----
train: 23.458847050983007
validation: 22.74
loss: 2.5693040874444626

---- 190 ----
train: 23.858713762079304
validation: 23.54
loss: 2.529674628900935

---- 199 ----
train: 24.458513828723756
validation: 23.9
loss: 2.4960833392405894

---- 0 ----
train: 24.099999999999998
validation: 24.08
loss: 2.4735252554166642

---- 10 ----
train: 25.133333333333336
validation: 24.58
loss: 2.4357728773865173

---- 20 ----
train: 25.733333333333334
validation: 25.040000000000003
loss: 2.4041379123169264

---- 30 ----
train: 26.3
validation: 25.64
loss: 2.3742560669474617

---- 40 ----
train: 26.700000000000003
validation: 26.240000000000002
loss: 2.3459911045220756

---- 50 ----
train: 26.966666666666665
validation: 26.700000000000003
loss: 2.3192206964710813

---- 60 ----
train: 27.333333333333332
validation: 27.26
loss: 2.2938340538980375

---- 70 ----
train: 27.866666666666667
validation: 27.88
loss: 2.269730322934522

---- 80 ----
train: 28.1
validation: 28.22
loss: 2.2468173353935343

---- 90 ----
train: 28.666666666666668
validation: 28.78
loss: 2.2250106220134502

---- 100 ----
train: 28.933333333333334
validation: 29.160000000000004
loss: 2.2042326167097817

---- 110 ----
train: 29.4
validation: 29.62
loss: 2.1844119982845425

---- 120 ----
train: 29.933333333333334
validation: 29.959999999999997
loss: 2.165483130874387

---- 130 ----
train: 30.233333333333334
validation: 30.28
loss: 2.1473855760492793

---- 140 ----
train: 30.433333333333334
validation: 30.64
loss: 2.1300636582001684

---- 150 ----
train: 31.0
validation: 30.959999999999997
loss: 2.113466071146898

---- 160 ----
train: 31.2
validation: 31.119999999999997
loss: 2.0975455182695466

---- 170 ----
train: 31.5
validation: 31.540000000000003
loss: 2.082258381383308

---- 180 ----
train: 31.7
validation: 31.900000000000002
loss: 2.0675644154235973

---- 190 ----
train: 31.833333333333336
validation: 32.12
loss: 2.053426467085708

---- 199 ----
train: 32.166666666666664
validation: 32.36
loss: 2.041149288294957

---- 0 ----
train: 32.86666666666667
validation: 32.6
loss: 2.078140717222804

---- 10 ----
train: 33.266666666666666
validation: 32.800000000000004
loss: 2.0608876245695065

---- 20 ----
train: 33.63333333333333
validation: 33.06
loss: 2.045988766757374

---- 30 ----
train: 33.96666666666667
validation: 33.36
loss: 2.031753024108371

---- 40 ----
train: 34.333333333333336
validation: 33.62
loss: 2.018123475809971

---- 50 ----
train: 34.599999999999994
validation: 33.94
loss: 2.0050506415814056

---- 60 ----
train: 34.96666666666667
validation: 34.14
loss: 1.9924908321122647

---- 70 ----
train: 35.233333333333334
validation: 34.260000000000005
loss: 1.9804052942452466

---- 80 ----
train: 35.43333333333333
validation: 34.54
loss: 1.9687595020518174

---- 90 ----
train: 35.733333333333334
validation: 34.660000000000004
loss: 1.9575225671136092

---- 100 ----
train: 36.13333333333333
validation: 34.82
loss: 1.94666674616533

---- 110 ----
train: 36.266666666666666
validation: 35.0
loss: 1.936167028305403

---- 120 ----
train: 36.36666666666667
validation: 35.18
loss: 1.9260007873681315

---- 130 ----
train: 36.666666666666664
validation: 35.480000000000004
loss: 1.9161474878093117

---- 140 ----
train: 37.166666666666664
validation: 35.8
loss: 1.9065884346865196

---- 150 ----
train: 37.36666666666667
validation: 35.980000000000004
loss: 1.8973065601097232

---- 160 ----
train: 37.6
validation: 36.24
loss: 1.888286239980346

---- 170 ----
train: 37.86666666666667
validation: 36.5
loss: 1.8795131359946344

---- 180 ----
train: 38.266666666666666
validation: 36.82
loss: 1.870974058816524

---- 190 ----
train: 38.5
validation: 37.019999999999996
loss: 1.8626568490718058

---- 199 ----
train: 38.766666666666666
validation: 37.08
loss: 1.8553517549662404

---- 0 ----
train: 37.8
validation: 36.88
loss: 1.9162272445966955

---- 10 ----
train: 38.166666666666664
validation: 37.18
loss: 1.9037048578116313

---- 20 ----
train: 38.233333333333334
validation: 37.26
loss: 1.8941425884019882

---- 30 ----
train: 38.4
validation: 37.4
loss: 1.885016700565756

---- 40 ----
train: 38.56666666666666
validation: 37.68
loss: 1.8762704794678648

---- 50 ----
train: 38.666666666666664
validation: 37.92
loss: 1.8678591894048626

---- 60 ----
train: 38.93333333333333
validation: 38.0
loss: 1.8597462687220845

---- 70 ----
train: 39.13333333333333
validation: 38.18
loss: 1.8519015960093168

---- 80 ----
train: 39.43333333333333
validation: 38.24
loss: 1.844300142840476

---- 90 ----
train: 39.56666666666667
validation: 38.42
loss: 1.8369209251795404

---- 100 ----
train: 39.83333333333333
validation: 38.48
loss: 1.8297461864390154

---- 110 ----
train: 40.0
validation: 38.64
loss: 1.822760759932121

---- 120 ----
train: 40.1
validation: 38.76
loss: 1.8159515701605649

---- 130 ----
train: 40.233333333333334
validation: 38.9
loss: 1.8093072415623137

---- 140 ----
train: 40.46666666666667
validation: 38.92
loss: 1.802817790496402

---- 150 ----
train: 40.699999999999996
validation: 39.0
loss: 1.7964743817859026

---- 160 ----
train: 40.833333333333336
validation: 38.98
loss: 1.7902691354203968

---- 170 ----
train: 40.833333333333336
validation: 39.14
loss: 1.7841949723173438

---- 180 ----
train: 40.9
validation: 39.28
loss: 1.778245490578256

---- 190 ----
train: 41.0
validation: 39.36
loss: 1.772414865625474

---- 199 ----
train: 41.16666666666667
validation: 39.56
loss: 1.7672645126867093

---- 0 ----
train: 40.56666666666667
validation: 39.800000000000004
loss: 1.7997472721777086

---- 10 ----
train: 40.9
validation: 39.92
loss: 1.7887290277438297

---- 20 ----
train: 41.13333333333333
validation: 40.160000000000004
loss: 1.7810230412363384

---- 30 ----
train: 41.46666666666667
validation: 40.22
loss: 1.7737105591645097

---- 40 ----
train: 41.8
validation: 40.42
loss: 1.7667319418760847

---- 50 ----
train: 41.9
validation: 40.56
loss: 1.7600406490037122

---- 60 ----
train: 42.13333333333333
validation: 40.6
loss: 1.753599162116409

---- 70 ----
train: 42.266666666666666
validation: 40.64
loss: 1.7473770352883191

---- 80 ----
train: 42.46666666666667
validation: 40.68
loss: 1.7413493997506422

---- 90 ----
train: 42.6
validation: 40.699999999999996
loss: 1.7354958035830605

---- 100 ----
train: 42.63333333333333
validation: 40.78
loss: 1.7297993081214753

---- 110 ----
train: 42.833333333333336
validation: 40.839999999999996
loss: 1.724245781747215

---- 120 ----
train: 42.9
validation: 40.96
loss: 1.7188233459270508

---- 130 ----
train: 43.0
validation: 41.08
loss: 1.7135219390896994

---- 140 ----
train: 43.166666666666664
validation: 41.02
loss: 1.708332972017008

---- 150 ----
train: 43.266666666666666
validation: 41.14
loss: 1.7032490545529473

---- 160 ----
train: 43.266666666666666
validation: 41.36
loss: 1.6982637780800929

---- 170 ----
train: 43.53333333333333
validation: 41.52
loss: 1.6933715417503075

---- 180 ----
train: 43.833333333333336
validation: 41.52
loss: 1.6885674131567248

---- 190 ----
train: 44.06666666666666
validation: 41.56
loss: 1.6838470162037165

---- 199 ----
train: 44.233333333333334
validation: 41.58
loss: 1.6796670091826005

---- 0 ----
train: 39.03333333333333
validation: 41.699999999999996
loss: 1.8311398782845407

---- 10 ----
train: 39.300000000000004
validation: 41.9
loss: 1.8201642804343434

---- 20 ----
train: 39.36666666666667
validation: 41.86
loss: 1.8133156776089214

---- 30 ----
train: 39.43333333333333
validation: 41.86
loss: 1.8068641024592806

---- 40 ----
train: 39.7
validation: 41.92
loss: 1.8007469215088288

---- 50 ----
train: 39.83333333333333
validation: 42.08
loss: 1.794913625382583

---- 60 ----
train: 39.83333333333333
validation: 42.18
loss: 1.7893231636867073

---- 70 ----
train: 39.900000000000006
validation: 42.34
loss: 1.7839421449434079

---- 80 ----
train: 39.96666666666667
validation: 42.32
loss: 1.778743350609805

---- 90 ----
train: 40.06666666666667
validation: 42.42
loss: 1.7737045225067332

---- 100 ----
train: 40.03333333333333
validation: 42.54
loss: 1.768807382321587

---- 110 ----
train: 40.1
validation: 42.6
loss: 1.7640368441561611

---- 120 ----
train: 40.300000000000004
validation: 42.66
loss: 1.7593803851933674

---- 130 ----
train: 40.46666666666667
validation: 42.76
loss: 1.7548275443568777

---- 140 ----
train: 40.53333333333333
validation: 42.8
loss: 1.7503695236581787

---- 150 ----
train: 40.6
validation: 42.96
loss: 1.7459988713854904

---- 160 ----
train: 40.8
validation: 42.9
loss: 1.7417092302143469

---- 170 ----
train: 40.9
validation: 42.96
loss: 1.7374951366561848

---- 180 ----
train: 40.96666666666667
validation: 42.96
loss: 1.7333518610307967

---- 190 ----
train: 41.06666666666667
validation: 43.08
loss: 1.7292752794050537

---- 199 ----
train: 41.16666666666667
validation: 43.059999999999995
loss: 1.7256603775304518

---- 0 ----
train: 41.86666666666667
validation: 43.0
loss: 1.7255328808772226

---- 10 ----
train: 42.199999999999996
validation: 43.14
loss: 1.7181932136667346

---- 20 ----
train: 42.16666666666667
validation: 43.24
loss: 1.7123058288748865

---- 30 ----
train: 42.233333333333334
validation: 43.34
loss: 1.7067335275471527

---- 40 ----
train: 42.3
validation: 43.419999999999995
loss: 1.701429640266641

---- 50 ----
train: 42.53333333333333
validation: 43.480000000000004
loss: 1.6963564573291006

---- 60 ----
train: 42.733333333333334
validation: 43.6
loss: 1.6914832932897288

---- 70 ----
train: 42.93333333333334
validation: 43.64
loss: 1.6867850433688742

---- 80 ----
train: 43.233333333333334
validation: 43.66
loss: 1.6822410492030762

---- 90 ----
train: 43.3
validation: 43.66
loss: 1.677834207091069

---- 100 ----
train: 43.43333333333334
validation: 43.8
loss: 1.6735502659628376

---- 110 ----
train: 43.6
validation: 43.88
loss: 1.669377273626852

---- 120 ----
train: 43.6
validation: 43.980000000000004
loss: 1.6653051388960118

---- 130 ----
train: 43.8
validation: 44.04
loss: 1.6613252843375501

---- 140 ----
train: 43.766666666666666
validation: 44.14
loss: 1.6574303699921478

---- 150 ----
train: 43.96666666666667
validation: 44.2
loss: 1.6536140727741324

---- 160 ----
train: 44.06666666666666
validation: 44.26
loss: 1.6498709096582012

---- 170 ----
train: 44.06666666666666
validation: 44.4
loss: 1.64619609538942

---- 180 ----
train: 44.266666666666666
validation: 44.56
loss: 1.642585427492964

---- 190 ----
train: 44.46666666666667
validation: 44.62
loss: 1.6390351929395333

---- 199 ----
train: 44.56666666666666
validation: 44.66
loss: 1.635888917661235

---- 0 ----
train: 45.300000000000004
validation: 44.84
loss: 1.6633146027727261

---- 10 ----
train: 45.36666666666667
validation: 44.82
loss: 1.6552122149679827

---- 20 ----
train: 45.5
validation: 44.9
loss: 1.6494776762196683

---- 30 ----
train: 45.63333333333333
validation: 44.98
loss: 1.6440635812685693

---- 40 ----
train: 45.766666666666666
validation: 45.019999999999996
loss: 1.6389251155613371

---- 50 ----
train: 45.86666666666667
validation: 45.0
loss: 1.63402553674509

---- 60 ----
train: 45.83333333333333
validation: 45.019999999999996
loss: 1.6293344709724236

---- 70 ----
train: 45.9
validation: 45.24
loss: 1.624826662193827

---- 80 ----
train: 46.13333333333333
validation: 45.08
loss: 1.6204809904234712

---- 90 ----
train: 46.1
validation: 45.019999999999996
loss: 1.6162796965395922

---- 100 ----
train: 46.13333333333333
validation: 45.04
loss: 1.6122077666802357

---- 110 ----
train: 46.233333333333334
validation: 45.2
loss: 1.6082524407008596

---- 120 ----
train: 46.43333333333333
validation: 45.22
loss: 1.6044028176312195

---- 130 ----
train: 46.53333333333333
validation: 45.300000000000004
loss: 1.6006495373970302

---- 140 ----
train: 46.6
validation: 45.379999999999995
loss: 1.5969845228278412

---- 150 ----
train: 46.7
validation: 45.42
loss: 1.5934007695675687

---- 160 ----
train: 46.766666666666666
validation: 45.440000000000005
loss: 1.5898921742371124

---- 170 ----
train: 46.833333333333336
validation: 45.519999999999996
loss: 1.5864533932884284

---- 180 ----
train: 46.96666666666667
validation: 45.540000000000006
loss: 1.5830797265958056

---- 190 ----
train: 47.13333333333333
validation: 45.48
loss: 1.579767021072094

---- 199 ----
train: 47.3
validation: 45.519999999999996
loss: 1.57683465275631

---- 0 ----
train: 44.43333333333334
validation: 45.879999999999995
loss: 1.6046056272420637

---- 10 ----
train: 44.9
validation: 45.739999999999995
loss: 1.5976131352782408

---- 20 ----
train: 44.93333333333333
validation: 45.82
loss: 1.5927937938342027

---- 30 ----
train: 44.83333333333333
validation: 46.06
loss: 1.5882127546719178

---- 40 ----
train: 44.9
validation: 46.12
loss: 1.58383696992973

---- 50 ----
train: 45.2
validation: 46.2
loss: 1.5796405258246904

---- 60 ----
train: 45.53333333333333
validation: 46.300000000000004
loss: 1.5756017785476613

---- 70 ----
train: 45.666666666666664
validation: 46.379999999999995
loss: 1.571702594099358

---- 80 ----
train: 45.93333333333333
validation: 46.379999999999995
loss: 1.567927726627628

---- 90 ----
train: 46.03333333333333
validation: 46.46
loss: 1.564264308334289

---- 100 ----
train: 46.166666666666664
validation: 46.5
loss: 1.5607014317829893

---- 110 ----
train: 46.300000000000004
validation: 46.54
loss: 1.5572298083047078

---- 120 ----
train: 46.400000000000006
validation: 46.58
loss: 1.5538414888025047

---- 130 ----
train: 46.56666666666667
validation: 46.6
loss: 1.5505296355588665

---- 140 ----
train: 46.666666666666664
validation: 46.7
loss: 1.5472883356343163

---- 150 ----
train: 46.9
validation: 46.86
loss: 1.5441124481298123

---- 160 ----
train: 46.93333333333333
validation: 46.92
loss: 1.5409974789964271

---- 170 ----
train: 46.93333333333333
validation: 47.04
loss: 1.5379394782454028

---- 180 ----
train: 47.06666666666667
validation: 47.06
loss: 1.5349349553750016

---- 190 ----
train: 47.03333333333333
validation: 46.98
loss: 1.5319808096197518

---- 199 ----
train: 47.06666666666667
validation: 47.02
loss: 1.5293628564701827

---- 0 ----
train: 47.599999999999994
validation: 47.160000000000004
loss: 1.5399009719275873

---- 10 ----
train: 48.233333333333334
validation: 47.260000000000005
loss: 1.5316201406027414

---- 20 ----
train: 48.3
validation: 47.22
loss: 1.5274757539436166

---- 30 ----
train: 48.5
validation: 47.32
loss: 1.5235344632773744

---- 40 ----
train: 48.63333333333333
validation: 47.4
loss: 1.5197690564980413

---- 50 ----
train: 48.63333333333333
validation: 47.599999999999994
loss: 1.5161573894197176

---- 60 ----
train: 48.833333333333336
validation: 47.64
loss: 1.5126809530754801

---- 70 ----
train: 48.93333333333334
validation: 47.88
loss: 1.509324206309499

---- 80 ----
train: 48.9
validation: 47.94
loss: 1.5060740399514236

---- 90 ----
train: 48.96666666666666
validation: 48.0
loss: 1.5029193450198097

---- 100 ----
train: 49.266666666666666
validation: 48.120000000000005
loss: 1.4998506636425393

---- 110 ----
train: 49.3
validation: 48.120000000000005
loss: 1.496859905945373

---- 120 ----
train: 49.43333333333334
validation: 48.18
loss: 1.4939401197079223

---- 130 ----
train: 49.46666666666666
validation: 48.26
loss: 1.4910853023532975

---- 140 ----
train: 49.46666666666666
validation: 48.22
loss: 1.4882902470004975

---- 150 ----
train: 49.5
validation: 48.26
loss: 1.4855504160047366

---- 160 ----
train: 49.63333333333333
validation: 48.28
loss: 1.4828618367442816

---- 170 ----
train: 49.666666666666664
validation: 48.22
loss: 1.4802210154638382

---- 180 ----
train: 49.7
validation: 48.28
loss: 1.4776248658157556

---- 190 ----
train: 49.7
validation: 48.3
loss: 1.47507064939932

---- 199 ----
train: 49.8
validation: 48.339999999999996
loss: 1.4728056853283094

